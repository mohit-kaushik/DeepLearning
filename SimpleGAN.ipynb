{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5), (0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST('./',train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f468cd344d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = dataset[2]\n",
    "plt.imshow(image[0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # random noise: 64\n",
    "        self.linear1 = torch.nn.Linear(64,256)\n",
    "        self.l_relu = torch.nn.LeakyReLU(0.1)\n",
    "        # out image 28 *28 -> 784\n",
    "        self.linear2  = torch.nn.Linear(256,784)\n",
    "        self.tan = torch.nn.Tanh()\n",
    "    def forward(self, img):\n",
    "        x1 = self.linear1(img.clone())\n",
    "        x2 = self.l_relu(x1.clone())\n",
    "        x3 = self.linear2(x2.clone())\n",
    "#         print(x.size())\n",
    "        x = self.tan(x3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(28*28,256)\n",
    "        self.l_relu = torch.nn.LeakyReLU(0.1)\n",
    "        self.linear2 = torch.nn.Linear(256,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self, img):\n",
    "        x1 = self.linear1(img)\n",
    "        x2 = self.l_relu(x1.clone())\n",
    "        x3 = self.linear2(x2.clone())\n",
    "        x = self.sigmoid(x3.clone())\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1\n",
    "disc = Discriminator().to(device)\n",
    "gen = Generator().to(device)\n",
    "\n",
    "optim_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "optim_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "disc_criteria = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [256, 784]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-7a1ef79b55e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#             l = loss.clone()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfake_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#             optim_disc.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [256, 784]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for real_img, _ in dataset:\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            real_img_flat = real_img.view(-1, 28*28*1)\n",
    "\n",
    "            random_noise = torch.randn(batch_size, 64).to(device)\n",
    "#             print(random_noise.size())\n",
    "            fake_img = gen(random_noise)\n",
    "#             print(fake_img.size())\n",
    "\n",
    "            # GEN\n",
    "            pred_fake_gen = disc(fake_img.clone())\n",
    "            loss_gen = disc_criteria(pred_fake_gen.clone(), torch.ones_like(pred_fake_gen.clone()))\n",
    "            optim_gen.zero_grad()\n",
    "            loss_gen.backward(retain_graph=True)\n",
    "            optim_gen.step()\n",
    "\n",
    "            # Disc\n",
    "            # If you want to use batch_size use Dataloader\n",
    "            pred_real = disc(real_img_flat.clone())\n",
    "            pred_fake = disc(torch.randn(1,784))\n",
    "#             print(pred_real)\n",
    "#             actual_out_real = torch.ones(1)\n",
    "#             actual_out_fake = torch.zeros(1)\n",
    "\n",
    "#             loss_real = disc_criteria(pred_real.clone(), actual_out_real.clone())\n",
    "#             loss_fake = disc_criteria(pred_fake.clone(), actual_out_fake.clone())\n",
    "#             loss = (loss_real.clone() + loss_fake.clone()) / 2\n",
    "#             disc.zero_grad()\n",
    "            # or optim_disc.zero_grad()\n",
    "#             print(fake_img)\n",
    "#             l = loss.clone()\n",
    "            m =  fake_img.clone().sum()\n",
    "            m.backward()\n",
    "#             optim_disc.step()\n",
    "            break\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'require_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-2f422a9610c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'require_grad'"
     ]
    }
   ],
   "source": [
    "torch.ones(32).require_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
